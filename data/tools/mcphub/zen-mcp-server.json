[
    {
        "name": "chat",
        "description": "General chat and collaborative thinking partner for brainstorming, development discussion, getting second opinions, and exploring ideas. Use for bouncing ideas, validating approaches, asking questions, and getting explanations. ",
        "parameters": {
            "type": "object",
            "properties": {
                "prompt": {
                    "type": "string",
                    "description": "Your question or idea for collaborative thinking. Provide detailed context, including your goal, what you've tried, and any specific challenges. CRITICAL: To discuss code, provide file paths using the 'files' parameter instead of pasting large code blocks here."
                },
                "files": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Absolute full-paths to existing files / folders for context. DO NOT SHORTEN."
                },
                "images": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Optional images for visual context (must be FULL absolute paths to real files / folders - DO NOT SHORTEN - OR these can be bas64 data)"
                },
                "model": {
                    "type": "string",
                    "description": "IMPORTANT: Use the model specified by the user if provided, OR select the most suitable model for this specific task based on the requirements and capabilities listed below:\n\nOpenAI models - Available when OPENAI_API_KEY is configured:\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'gpt-5-mini': GPT-5-mini (400K context, 128K output) - Efficient variant with reasoning support\n- 'gpt-5-nano': GPT-5 nano (400K context) - Fastest, cheapest version of GPT-5 for summarization and classification tasks\n- 'o3': Strong reasoning (200K context) - Logical problems, code generation, systematic analysis\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window",
                    "enum": [
                        "gpt-4.1",
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt4.1",
                        "gpt5",
                        "gpt5-mini",
                        "gpt5-nano",
                        "gpt5mini",
                        "gpt5nano",
                        "mini",
                        "nano",
                        "o3",
                        "o3-mini",
                        "o3-pro",
                        "o3mini",
                        "o4-mini",
                        "o4mini"
                    ]
                },
                "temperature": {
                    "type": "number",
                    "description": "Lower values: focused/deterministic; higher: creative. Tool-specific defaults apply if unspecified.",
                    "minimum": 0,
                    "maximum": 1
                },
                "thinking_mode": {
                    "type": "string",
                    "enum": [
                        "minimal",
                        "low",
                        "medium",
                        "high",
                        "max"
                    ],
                    "description": "Thinking depth: minimal (0.5%), low (8%), medium (33%), high (67%), max (100% of model max). Higher modes: deeper reasoning but slower."
                },
                "use_websearch": {
                    "type": "boolean",
                    "description": "Enable web search for docs and current info. Model can request Claude to perform web-search for best practices, framework docs, solution research, latest API information.",
                    "default": true
                },
                "continuation_id": {
                    "type": "string",
                    "description": "Unique thread continuation ID for multi-turn conversations. Reuse last continuation_id when continuing discussion (unless user provides different ID) using exact unique identifer. Embeds complete conversation history. Build upon history without repeating. Focus on new insights. Works across different tools."
                }
            },
            "required": [
                "prompt",
                "model"
            ]
        }
    },
    {
        "name": "thinkdeep",
        "description": "Performs multi-stage investigation and reasoning for complex problem analysis. Use for architecture decisions, complex bugs, performance challenges, and security analysis. Provides systematic hypothesis testing, evidence-based investigation, and expert validation.",
        "parameters": {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "type": "object",
            "properties": {
                "step": {
                    "type": "string",
                    "description": "Current work step content and findings from your overall work"
                },
                "step_number": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Current step number in work sequence (starts at 1)"
                },
                "total_steps": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Estimated total steps needed to complete work"
                },
                "next_step_required": {
                    "type": "boolean",
                    "description": "Whether another work step is needed. When false, aim to reduce total_steps to match step_number to avoid mismatch."
                },
                "findings": {
                    "type": "string",
                    "description": "Important findings, evidence and insights discovered in this step"
                },
                "files_checked": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "List of files examined during this work step"
                },
                "relevant_files": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Files identified as relevant to issue/goal (FULL absolute paths to real files/folders - DO NOT SHORTEN)"
                },
                "relevant_context": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Methods/functions identified as involved in the issue"
                },
                "issues_found": {
                    "type": "array",
                    "items": {
                        "type": "object"
                    },
                    "description": "Issues identified with severity levels during work"
                },
                "confidence": {
                    "type": "string",
                    "enum": [
                        "exploring",
                        "low",
                        "medium",
                        "high",
                        "very_high",
                        "almost_certain",
                        "certain"
                    ],
                    "description": "Confidence level: exploring (just starting), low (early investigation), medium (some evidence), high (strong evidence), very_high (comprehensive understanding), almost_certain (near complete confidence), certain (100% confidence locally - no external validation needed)"
                },
                "hypothesis": {
                    "type": "string",
                    "description": "Current theory about issue/goal based on work"
                },
                "backtrack_from_step": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Step number to backtrack from if work needs revision"
                },
                "use_assistant_model": {
                    "type": "boolean",
                    "default": true,
                    "description": "Use assistant model for expert analysis after workflow steps. False skips expert analysis, relies solely on Claude's investigation. Defaults to True for comprehensive validation."
                },
                "temperature": {
                    "type": "number",
                    "description": "Lower values: focused/deterministic; higher: creative. Tool-specific defaults apply if unspecified.",
                    "minimum": 0.0,
                    "maximum": 1.0
                },
                "thinking_mode": {
                    "type": "string",
                    "enum": [
                        "minimal",
                        "low",
                        "medium",
                        "high",
                        "max"
                    ],
                    "description": "Thinking depth: minimal (0.5%), low (8%), medium (33%), high (67%), max (100% of model max). Higher modes: deeper reasoning but slower."
                },
                "use_websearch": {
                    "type": "boolean",
                    "description": "Enable web search for docs and current info. Model can request Claude to perform web-search for best practices, framework docs, solution research, latest API information.",
                    "default": true
                },
                "continuation_id": {
                    "type": "string",
                    "description": "Unique thread continuation ID for multi-turn conversations. Reuse last continuation_id when continuing discussion (unless user provides different ID) using exact unique identifer. Embeds complete conversation history. Build upon history without repeating. Focus on new insights. Works across different tools."
                },
                "images": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Optional images for visual context. MUST be absolute paths or base64. Use when user mentions images. Describe image contents. "
                },
                "model": {
                    "type": "string",
                    "description": "IMPORTANT: Use the model specified by the user if provided, OR select the most suitable model for this specific task based on the requirements and capabilities listed below:\n\nOpenAI models - Available when OPENAI_API_KEY is configured:\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'gpt-5-mini': GPT-5-mini (400K context, 128K output) - Efficient variant with reasoning support\n- 'gpt-5-nano': GPT-5 nano (400K context) - Fastest, cheapest version of GPT-5 for summarization and classification tasks\n- 'o3': Strong reasoning (200K context) - Logical problems, code generation, systematic analysis\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window",
                    "enum": [
                        "gpt-4.1",
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt4.1",
                        "gpt5",
                        "gpt5-mini",
                        "gpt5-nano",
                        "gpt5mini",
                        "gpt5nano",
                        "mini",
                        "nano",
                        "o3",
                        "o3-mini",
                        "o3-pro",
                        "o3mini",
                        "o4-mini",
                        "o4mini"
                    ]
                },
                "problem_context": {
                    "type": "string",
                    "description": "Additional context about problem/goal. Be expressive."
                },
                "focus_areas": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Focus aspects (architecture, performance, security, etc.)"
                }
            },
            "required": [
                "step",
                "step_number",
                "total_steps",
                "next_step_required",
                "findings",
                "model"
            ],
            "additionalProperties": false,
            "title": "ThinkdeepRequest"
        }
    },
    {
        "name": "planner",
        "description": "Breaks down complex tasks through interactive, sequential planning with revision and branching capabilities. Use for complex project planning, system design, migration strategies, and architectural decisions. Builds plans incrementally with deep reflection for complex scenarios.",
        "parameters": {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "type": "object",
            "properties": {
                "step": {
                    "type": "string",
                    "description": "Your current planning step content. Step 1: Describe the task/problem to plan in detail for breakdown. Subsequent steps: Provide planning content (steps, revisions, questions, approach changes, etc.)."
                },
                "step_number": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Current step number in work sequence (starts at 1)"
                },
                "total_steps": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Estimated total steps needed to complete work"
                },
                "next_step_required": {
                    "type": "boolean",
                    "description": "Whether another work step is needed. When false, aim to reduce total_steps to match step_number to avoid mismatch."
                },
                "use_assistant_model": {
                    "type": "boolean",
                    "default": true,
                    "description": "Use assistant model for expert analysis after workflow steps. False skips expert analysis, relies solely on Claude's investigation. Defaults to True for comprehensive validation."
                },
                "continuation_id": {
                    "type": "string",
                    "description": "Unique thread continuation ID for multi-turn conversations. Reuse last continuation_id when continuing discussion (unless user provides different ID) using exact unique identifer. Embeds complete conversation history. Build upon history without repeating. Focus on new insights. Works across different tools."
                },
                "model": {
                    "type": "string",
                    "description": "IMPORTANT: Use the model specified by the user if provided, OR select the most suitable model for this specific task based on the requirements and capabilities listed below:\n\nOpenAI models - Available when OPENAI_API_KEY is configured:\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'gpt-5-mini': GPT-5-mini (400K context, 128K output) - Efficient variant with reasoning support\n- 'gpt-5-nano': GPT-5 nano (400K context) - Fastest, cheapest version of GPT-5 for summarization and classification tasks\n- 'o3': Strong reasoning (200K context) - Logical problems, code generation, systematic analysis\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window",
                    "enum": [
                        "gpt-4.1",
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt4.1",
                        "gpt5",
                        "gpt5-mini",
                        "gpt5-nano",
                        "gpt5mini",
                        "gpt5nano",
                        "mini",
                        "nano",
                        "o3",
                        "o3-mini",
                        "o3-pro",
                        "o3mini",
                        "o4-mini",
                        "o4mini"
                    ]
                },
                "is_step_revision": {
                    "type": "boolean",
                    "description": "True if this step revises/replaces a previous step"
                },
                "revises_step_number": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "If is_step_revision is true, which step number is being revised"
                },
                "is_branch_point": {
                    "type": "boolean",
                    "description": "True if this step branches from a previous step to explore alternatives"
                },
                "branch_from_step": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "If is_branch_point is true, which step number is the branching point"
                },
                "branch_id": {
                    "type": "string",
                    "description": "Identifier for the current branch (e.g., 'approach-A', 'microservices-path')"
                },
                "more_steps_needed": {
                    "type": "boolean",
                    "description": "True if more steps are needed beyond the initial estimate"
                }
            },
            "required": [
                "step",
                "step_number",
                "total_steps",
                "next_step_required",
                "model"
            ],
            "additionalProperties": false,
            "title": "PlannerRequest"
        }
    },
    {
        "name": "consensus",
        "description": "Builds multi-model consensus through systematic analysis and structured debate. Use for complex decisions, architectural choices, feature proposals, and technology evaluations. Consults multiple models with different stances to synthesize comprehensive recommendations.",
        "parameters": {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "type": "object",
            "properties": {
                "step": {
                    "type": "string",
                    "description": "The core question for consensus. Step 1: Provide the EXACT proposal for all models to evaluate. CRITICAL: This text is sent to all models and must be a clear question, not a self-referential statement (e.g., use 'Evaluate...' not 'I will evaluate...'). Steps 2+: Internal notes on the last model's response; this is NOT sent to other models."
                },
                "step_number": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "The index of the current step in the consensus workflow, beginning at 1. Step 1 is your analysis, steps 2+ are for processing individual model responses."
                },
                "total_steps": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Total number of steps needed. This equals the number of models to consult. Step 1 includes your analysis + first model consultation on return of the call. Final step includes last model consultation + synthesis."
                },
                "next_step_required": {
                    "type": "boolean",
                    "description": "Set to true if more models need to be consulted. False when ready for final synthesis."
                },
                "findings": {
                    "type": "string",
                    "description": "Your analysis of the consensus topic. Step 1: Your independent, comprehensive analysis of the proposal. CRITICAL: This is for the final synthesis and is NOT sent to the other models. Steps 2+: A summary of the key points from the most recent model's response."
                },
                "relevant_files": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Files that are relevant to the consensus analysis. Include files that help understand the proposal, provide context, or contain implementation details."
                },
                "use_assistant_model": {
                    "type": "boolean",
                    "default": true,
                    "description": "Use assistant model for expert analysis after workflow steps. False skips expert analysis, relies solely on Claude's investigation. Defaults to True for comprehensive validation."
                },
                "continuation_id": {
                    "type": "string",
                    "description": "Unique thread continuation ID for multi-turn conversations. Reuse last continuation_id when continuing discussion (unless user provides different ID) using exact unique identifer. Embeds complete conversation history. Build upon history without repeating. Focus on new insights. Works across different tools."
                },
                "images": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Optional list of image paths or base64 data URLs for visual context. Useful for UI/UX discussions, architecture diagrams, mockups, or any visual references that help inform the consensus analysis."
                },
                "model": {
                    "type": "string",
                    "description": "IMPORTANT: Use the model specified by the user if provided, OR select the most suitable model for this specific task based on the requirements and capabilities listed below:\n\nOpenAI models - Available when OPENAI_API_KEY is configured:\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'gpt-5-mini': GPT-5-mini (400K context, 128K output) - Efficient variant with reasoning support\n- 'gpt-5-nano': GPT-5 nano (400K context) - Fastest, cheapest version of GPT-5 for summarization and classification tasks\n- 'o3': Strong reasoning (200K context) - Logical problems, code generation, systematic analysis\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window",
                    "enum": [
                        "gpt-4.1",
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt4.1",
                        "gpt5",
                        "gpt5-mini",
                        "gpt5-nano",
                        "gpt5mini",
                        "gpt5nano",
                        "mini",
                        "nano",
                        "o3",
                        "o3-mini",
                        "o3-pro",
                        "o3mini",
                        "o4-mini",
                        "o4mini"
                    ]
                },
                "models": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "model": {
                                "type": "string"
                            },
                            "stance": {
                                "type": "string",
                                "enum": [
                                    "for",
                                    "against",
                                    "neutral"
                                ],
                                "default": "neutral"
                            },
                            "stance_prompt": {
                                "type": "string"
                            }
                        },
                        "required": [
                            "model"
                        ]
                    },
                    "description": "List of model configurations to consult. Each can have a model name, stance (for/against/neutral), and optional custom stance prompt. The same model can be used multiple times with different stances, but each model + stance combination must be unique. Example: [{'model': 'o3', 'stance': 'for'}, {'model': 'o3', 'stance': 'against'}, {'model': 'flash', 'stance': 'neutral'}]"
                },
                "current_model_index": {
                    "type": "integer",
                    "minimum": 0,
                    "description": "Internal tracking of which model is being consulted (0-based index). Used to determine which model to call next."
                },
                "model_responses": {
                    "type": "array",
                    "items": {
                        "type": "object"
                    },
                    "description": "Accumulated responses from models consulted so far. Internal field for tracking progress."
                }
            },
            "required": [
                "step",
                "step_number",
                "total_steps",
                "next_step_required",
                "findings"
            ],
            "additionalProperties": false,
            "title": "ConsensusRequest"
        }
    },
    {
        "name": "codereview",
        "description": "Performs systematic, step-by-step code review with expert validation. Use for comprehensive analysis covering quality, security, performance, and architecture. Guides through structured investigation to ensure thoroughness.",
        "parameters": {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "type": "object",
            "properties": {
                "step": {
                    "type": "string",
                    "description": "Review plan. Step 1: State strategy. Later: Report findings. MUST examine quality, security, performance, architecture. Use 'relevant_files' for code. NO large snippets."
                },
                "step_number": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Current step index in review sequence (starts at 1). Build upon previous steps."
                },
                "total_steps": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Estimated steps needed to complete the review. IMPORTANT: For external validation, max 2 steps. For internal validation, use 1 step. When continuation_id is provided (continuing a previous conversation), set to 2 max for external, 1 for internal."
                },
                "next_step_required": {
                    "type": "boolean",
                    "description": "True to continue with another step, False when review is complete. CRITICAL for external validation: Set to True on step 1, then False on step 2. For internal validation: Set to False immediately. When continuation_id is provided: Follow the same rules based on validation type."
                },
                "findings": {
                    "type": "string",
                    "description": "Discoveries: quality, security, performance, architecture. Document positive+negative. Update in later steps."
                },
                "files_checked": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "All examined files (absolute paths), including ruled-out ones."
                },
                "relevant_files": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Step 1: All files/dirs for review. Final: Subset with key findings (issues, patterns, decisions)."
                },
                "relevant_context": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Methods/functions identified as involved in the issue"
                },
                "issues_found": {
                    "type": "array",
                    "items": {
                        "type": "object"
                    },
                    "description": "Issues with 'severity' (critical/high/medium/low) and 'description'. Vulnerabilities, performance, quality."
                },
                "confidence": {
                    "type": "string",
                    "enum": [
                        "exploring",
                        "low",
                        "medium",
                        "high",
                        "very_high",
                        "almost_certain",
                        "certain"
                    ],
                    "description": "Confidence level: exploring (just starting), low (early investigation), medium (some evidence), high (strong evidence), very_high (comprehensive understanding), almost_certain (near complete confidence), certain (100% confidence locally - no external validation needed)"
                },
                "hypothesis": {
                    "type": "string",
                    "description": "Current theory about issue/goal based on work"
                },
                "backtrack_from_step": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Step number to backtrack from if revision needed."
                },
                "use_assistant_model": {
                    "type": "boolean",
                    "default": true,
                    "description": "Use assistant model for expert analysis after workflow steps. False skips expert analysis, relies solely on Claude's investigation. Defaults to True for comprehensive validation."
                },
                "temperature": {
                    "type": "number",
                    "description": "Lower values: focused/deterministic; higher: creative. Tool-specific defaults apply if unspecified.",
                    "minimum": 0.0,
                    "maximum": 1.0
                },
                "thinking_mode": {
                    "type": "string",
                    "enum": [
                        "minimal",
                        "low",
                        "medium",
                        "high",
                        "max"
                    ],
                    "description": "Thinking depth: minimal (0.5%), low (8%), medium (33%), high (67%), max (100% of model max). Higher modes: deeper reasoning but slower."
                },
                "use_websearch": {
                    "type": "boolean",
                    "description": "Enable web search for docs and current info. Model can request Claude to perform web-search for best practices, framework docs, solution research, latest API information.",
                    "default": true
                },
                "continuation_id": {
                    "type": "string",
                    "description": "Unique thread continuation ID for multi-turn conversations. Reuse last continuation_id when continuing discussion (unless user provides different ID) using exact unique identifer. Embeds complete conversation history. Build upon history without repeating. Focus on new insights. Works across different tools."
                },
                "images": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Optional diagrams, mockups, visuals for review context (absolute paths). Include if materially helpful."
                },
                "model": {
                    "type": "string",
                    "description": "IMPORTANT: Use the model specified by the user if provided, OR select the most suitable model for this specific task based on the requirements and capabilities listed below:\n\nOpenAI models - Available when OPENAI_API_KEY is configured:\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'gpt-5-mini': GPT-5-mini (400K context, 128K output) - Efficient variant with reasoning support\n- 'gpt-5-nano': GPT-5 nano (400K context) - Fastest, cheapest version of GPT-5 for summarization and classification tasks\n- 'o3': Strong reasoning (200K context) - Logical problems, code generation, systematic analysis\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window",
                    "enum": [
                        "gpt-4.1",
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt4.1",
                        "gpt5",
                        "gpt5-mini",
                        "gpt5-nano",
                        "gpt5mini",
                        "gpt5nano",
                        "mini",
                        "nano",
                        "o3",
                        "o3-mini",
                        "o3-pro",
                        "o3mini",
                        "o4-mini",
                        "o4mini"
                    ]
                },
                "review_validation_type": {
                    "type": "string",
                    "enum": [
                        "external",
                        "internal"
                    ],
                    "default": "external",
                    "description": "'external' (default, expert model) or 'internal' (no expert). Default external unless user specifies."
                },
                "review_type": {
                    "type": "string",
                    "enum": [
                        "full",
                        "security",
                        "performance",
                        "quick"
                    ],
                    "default": "full",
                    "description": "Review type: full, security, performance, quick."
                },
                "focus_on": {
                    "type": "string",
                    "description": "Specific aspects or context for areas of concern."
                },
                "standards": {
                    "type": "string",
                    "description": "Coding standards to enforce."
                },
                "severity_filter": {
                    "type": "string",
                    "enum": [
                        "critical",
                        "high",
                        "medium",
                        "low",
                        "all"
                    ],
                    "default": "all",
                    "description": "Minimum severity to report."
                }
            },
            "required": [
                "step",
                "step_number",
                "total_steps",
                "next_step_required",
                "findings",
                "model"
            ],
            "additionalProperties": false,
            "title": "CodereviewRequest"
        }
    },
    {
        "name": "precommit",
        "description": "Validates git changes and repository state before committing with systematic analysis. Use for multi-repository validation, security review, change impact assessment, and completeness verification. Guides through structured investigation with expert analysis.",
        "parameters": {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "type": "object",
            "properties": {
                "step": {
                    "type": "string",
                    "description": "Validation plan. Step 1: State strategy. Later: Report findings. MUST examine git changes, analyze impacts. Use 'relevant_files' for code. NO large snippets."
                },
                "step_number": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Current step index in pre-commit sequence (starts at 1). Build upon previous steps."
                },
                "total_steps": {
                    "type": "integer",
                    "minimum": 3,
                    "description": "Estimated steps needed to complete validation. IMPORTANT: For external validation, use max 3 steps. For internal validation, use 1 step. When continuation_id is provided (continuing a previous conversation), set to 3 max for external, 1 for internal."
                },
                "next_step_required": {
                    "type": "boolean",
                    "description": "True to continue with another step, False when validation is complete. CRITICAL: If total_steps>=3, set to True until the final step. When continuation_id is provided: Follow the same validation rules based on precommit_type."
                },
                "findings": {
                    "type": "string",
                    "description": "Discoveries: git diffs, modifications, issues (bugs, missing tests, security). Document positive+concerns. Update in later steps."
                },
                "files_checked": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "All examined files (absolute paths), including ruled-out ones."
                },
                "relevant_files": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Files with changes or relevant to validation (absolute paths). Modified files, config, tests, docs."
                },
                "relevant_context": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Methods/functions identified as involved in the issue"
                },
                "issues_found": {
                    "type": "array",
                    "items": {
                        "type": "object"
                    },
                    "description": "Issues with 'severity' (critical/high/medium/low) and 'description'. Bugs, security, performance."
                },
                "confidence": {
                    "type": "string",
                    "enum": [
                        "exploring",
                        "low",
                        "medium",
                        "high",
                        "very_high",
                        "almost_certain",
                        "certain"
                    ],
                    "description": "Confidence level: exploring (just starting), low (early investigation), medium (some evidence), high (strong evidence), very_high (comprehensive understanding), almost_certain (near complete confidence), certain (100% confidence locally - no external validation needed)"
                },
                "hypothesis": {
                    "type": "string",
                    "description": "Current theory about issue/goal based on work"
                },
                "backtrack_from_step": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Step number to backtrack from if revision needed."
                },
                "use_assistant_model": {
                    "type": "boolean",
                    "default": true,
                    "description": "Use assistant model for expert analysis after workflow steps. False skips expert analysis, relies solely on Claude's investigation. Defaults to True for comprehensive validation."
                },
                "temperature": {
                    "type": "number",
                    "description": "Lower values: focused/deterministic; higher: creative. Tool-specific defaults apply if unspecified.",
                    "minimum": 0.0,
                    "maximum": 1.0
                },
                "thinking_mode": {
                    "type": "string",
                    "enum": [
                        "minimal",
                        "low",
                        "medium",
                        "high",
                        "max"
                    ],
                    "description": "Thinking depth: minimal (0.5%), low (8%), medium (33%), high (67%), max (100% of model max). Higher modes: deeper reasoning but slower."
                },
                "use_websearch": {
                    "type": "boolean",
                    "description": "Enable web search for docs and current info. Model can request Claude to perform web-search for best practices, framework docs, solution research, latest API information.",
                    "default": true
                },
                "continuation_id": {
                    "type": "string",
                    "description": "Unique thread continuation ID for multi-turn conversations. Reuse last continuation_id when continuing discussion (unless user provides different ID) using exact unique identifer. Embeds complete conversation history. Build upon history without repeating. Focus on new insights. Works across different tools."
                },
                "images": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Optional screenshots/visuals for validation (absolute paths)."
                },
                "model": {
                    "type": "string",
                    "description": "IMPORTANT: Use the model specified by the user if provided, OR select the most suitable model for this specific task based on the requirements and capabilities listed below:\n\nOpenAI models - Available when OPENAI_API_KEY is configured:\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'gpt-5-mini': GPT-5-mini (400K context, 128K output) - Efficient variant with reasoning support\n- 'gpt-5-nano': GPT-5 nano (400K context) - Fastest, cheapest version of GPT-5 for summarization and classification tasks\n- 'o3': Strong reasoning (200K context) - Logical problems, code generation, systematic analysis\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window",
                    "enum": [
                        "gpt-4.1",
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt4.1",
                        "gpt5",
                        "gpt5-mini",
                        "gpt5-nano",
                        "gpt5mini",
                        "gpt5nano",
                        "mini",
                        "nano",
                        "o3",
                        "o3-mini",
                        "o3-pro",
                        "o3mini",
                        "o4-mini",
                        "o4mini"
                    ]
                },
                "precommit_type": {
                    "type": "string",
                    "enum": [
                        "external",
                        "internal"
                    ],
                    "default": "external",
                    "description": "'external' (default, expert review) or 'internal' (local only). Default external unless user specifies."
                },
                "path": {
                    "type": "string",
                    "description": "Starting path for git repos (FULL absolute path). REQUIRED step 1."
                },
                "compare_to": {
                    "type": "string",
                    "description": "Optional git ref (branch/tag/commit) to compare. Checks remotes if needed. Without: checks staged/unstaged."
                },
                "include_staged": {
                    "type": "boolean",
                    "default": true,
                    "description": "Analyze staged changes. Ignored if 'compare_to' provided."
                },
                "include_unstaged": {
                    "type": "boolean",
                    "default": true,
                    "description": "Analyze unstaged changes. Ignored if 'compare_to' provided."
                },
                "focus_on": {
                    "type": "string",
                    "description": "Focus aspects: security, performance, test coverage."
                },
                "severity_filter": {
                    "type": "string",
                    "enum": [
                        "critical",
                        "high",
                        "medium",
                        "low",
                        "all"
                    ],
                    "default": "all",
                    "description": "Minimum severity to report."
                }
            },
            "required": [
                "step",
                "step_number",
                "total_steps",
                "next_step_required",
                "findings",
                "model"
            ],
            "additionalProperties": false,
            "title": "PrecommitRequest"
        }
    },
    {
        "name": "debug",
        "description": "Performs systematic debugging and root cause analysis for any type of issue. Use for complex bugs, mysterious errors, performance issues, race conditions, memory leaks, and integration problems. Guides through structured investigation with hypothesis testing and expert analysis.",
        "parameters": {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "type": "object",
            "properties": {
                "step": {
                    "type": "string",
                    "description": "Investigation step. Step 1: State issue+direction. Symptoms misleading; 'no bug' valid. Trace dependencies, verify hypotheses. Use relevant_files for code; this for text only."
                },
                "step_number": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Current step index (starts at 1). Build upon previous steps."
                },
                "total_steps": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Estimated total steps needed to complete the investigation. Adjust as new findings emerge. IMPORTANT: When continuation_id is provided (continuing a previous conversation), set this to 1 as we're not starting a new multi-step investigation."
                },
                "next_step_required": {
                    "type": "boolean",
                    "description": "True if you plan to continue the investigation with another step. False means root cause is known or investigation is complete. IMPORTANT: When continuation_id is provided (continuing a previous conversation), set this to False to immediately proceed with expert analysis."
                },
                "findings": {
                    "type": "string",
                    "description": "Discoveries: clues, code/log evidence, disproven theories. Be specific. If no bug found, document clearly as valid."
                },
                "files_checked": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "All examined files (absolute paths), including ruled-out ones."
                },
                "relevant_files": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Files directly relevant to issue (absolute paths). Cause, trigger, or manifestation locations."
                },
                "relevant_context": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Methods/functions identified as involved in the issue"
                },
                "issues_found": {
                    "type": "array",
                    "items": {
                        "type": "object"
                    },
                    "description": "Issues identified with severity levels during work"
                },
                "confidence": {
                    "type": "string",
                    "enum": [
                        "exploring",
                        "low",
                        "medium",
                        "high",
                        "very_high",
                        "almost_certain",
                        "certain"
                    ],
                    "description": "Your confidence in the hypothesis: exploring (starting out), low (early idea), medium (some evidence), high (strong evidence), very_high (very strong evidence), almost_certain (nearly confirmed), certain (100% confidence - root cause and fix are both confirmed locally with no need for external validation). WARNING: Do NOT use 'certain' unless the issue can be fully resolved with a fix, use 'very_high' or 'almost_certain' instead when not 100% sure. Using 'certain' means you have ABSOLUTE confidence locally and PREVENTS external model validation."
                },
                "hypothesis": {
                    "type": "string",
                    "description": "Concrete root cause theory from evidence. Can revise. Valid: 'No bug found - user misunderstanding' or 'Symptoms unrelated to code' if supported."
                },
                "backtrack_from_step": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Step number to backtrack from if revision needed."
                },
                "use_assistant_model": {
                    "type": "boolean",
                    "default": true,
                    "description": "Use assistant model for expert analysis after workflow steps. False skips expert analysis, relies solely on Claude's investigation. Defaults to True for comprehensive validation."
                },
                "temperature": {
                    "type": "number",
                    "description": "Lower values: focused/deterministic; higher: creative. Tool-specific defaults apply if unspecified.",
                    "minimum": 0.0,
                    "maximum": 1.0
                },
                "thinking_mode": {
                    "type": "string",
                    "enum": [
                        "minimal",
                        "low",
                        "medium",
                        "high",
                        "max"
                    ],
                    "description": "Thinking depth: minimal (0.5%), low (8%), medium (33%), high (67%), max (100% of model max). Higher modes: deeper reasoning but slower."
                },
                "use_websearch": {
                    "type": "boolean",
                    "description": "Enable web search for docs and current info. Model can request Claude to perform web-search for best practices, framework docs, solution research, latest API information.",
                    "default": true
                },
                "continuation_id": {
                    "type": "string",
                    "description": "Unique thread continuation ID for multi-turn conversations. Reuse last continuation_id when continuing discussion (unless user provides different ID) using exact unique identifer. Embeds complete conversation history. Build upon history without repeating. Focus on new insights. Works across different tools."
                },
                "images": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Optional screenshots/visuals clarifying issue (absolute paths)."
                },
                "model": {
                    "type": "string",
                    "description": "IMPORTANT: Use the model specified by the user if provided, OR select the most suitable model for this specific task based on the requirements and capabilities listed below:\n\nOpenAI models - Available when OPENAI_API_KEY is configured:\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'gpt-5-mini': GPT-5-mini (400K context, 128K output) - Efficient variant with reasoning support\n- 'gpt-5-nano': GPT-5 nano (400K context) - Fastest, cheapest version of GPT-5 for summarization and classification tasks\n- 'o3': Strong reasoning (200K context) - Logical problems, code generation, systematic analysis\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window",
                    "enum": [
                        "gpt-4.1",
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt4.1",
                        "gpt5",
                        "gpt5-mini",
                        "gpt5-nano",
                        "gpt5mini",
                        "gpt5nano",
                        "mini",
                        "nano",
                        "o3",
                        "o3-mini",
                        "o3-pro",
                        "o3mini",
                        "o4-mini",
                        "o4mini"
                    ]
                }
            },
            "required": [
                "step",
                "step_number",
                "total_steps",
                "next_step_required",
                "findings",
                "model"
            ],
            "additionalProperties": false,
            "title": "DebugRequest"
        }
    },
    {
        "name": "secaudit",
        "description": "Performs comprehensive security audit with systematic vulnerability assessment. Use for OWASP Top 10 analysis, compliance evaluation, threat modeling, and security architecture review. Guides through structured security investigation with expert validation.",
        "parameters": {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "type": "object",
            "properties": {
                "step": {
                    "type": "string",
                    "description": "Audit plan. Step 1: State strategy. Later: Report findings. MANDATORY: Systematic approach (OWASP Top 10, auth, validation). Use 'relevant_files'. NO large code."
                },
                "step_number": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Current step in audit sequence (starts at 1)."
                },
                "total_steps": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Estimated steps for audit. Adjust as findings emerge."
                },
                "next_step_required": {
                    "type": "boolean",
                    "description": "True to continue. False when ALL threats uncovered, ready for validation."
                },
                "findings": {
                    "type": "string",
                    "description": "Discoveries: vulnerabilities, auth issues, validation gaps, compliance. Document positives and concerns. Update past findings."
                },
                "files_checked": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "All files examined (absolute paths). Include ruled-out files."
                },
                "relevant_files": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Step 1: Files to audit (absolute paths). Final: Files with security issues, auth modules, config files."
                },
                "relevant_context": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Methods/functions identified as involved in the issue"
                },
                "issues_found": {
                    "type": "array",
                    "items": {
                        "type": "object"
                    },
                    "description": "Security issues as dict: 'severity' (critical/high/medium/low), 'description'. Include vulnerabilities, auth flaws, injection, crypto weakness, config issues."
                },
                "confidence": {
                    "type": "string",
                    "enum": [
                        "exploring",
                        "low",
                        "medium",
                        "high",
                        "very_high",
                        "almost_certain",
                        "certain"
                    ],
                    "description": "exploring/low/medium/high/very_high/almost_certain/certain. CRITICAL: 'certain' PREVENTS external validation."
                },
                "hypothesis": {
                    "type": "string",
                    "description": "Current theory about issue/goal based on work"
                },
                "backtrack_from_step": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Step number to backtrack from if revision needed."
                },
                "use_assistant_model": {
                    "type": "boolean",
                    "default": true,
                    "description": "Use assistant model for expert analysis after workflow steps. False skips expert analysis, relies solely on Claude's investigation. Defaults to True for comprehensive validation."
                },
                "temperature": {
                    "type": "number",
                    "description": "Lower values: focused/deterministic; higher: creative. Tool-specific defaults apply if unspecified.",
                    "minimum": 0.0,
                    "maximum": 1.0
                },
                "thinking_mode": {
                    "type": "string",
                    "enum": [
                        "minimal",
                        "low",
                        "medium",
                        "high",
                        "max"
                    ],
                    "description": "Thinking depth: minimal (0.5%), low (8%), medium (33%), high (67%), max (100% of model max). Higher modes: deeper reasoning but slower."
                },
                "use_websearch": {
                    "type": "boolean",
                    "description": "Enable web search for docs and current info. Model can request Claude to perform web-search for best practices, framework docs, solution research, latest API information.",
                    "default": true
                },
                "continuation_id": {
                    "type": "string",
                    "description": "Unique thread continuation ID for multi-turn conversations. Reuse last continuation_id when continuing discussion (unless user provides different ID) using exact unique identifer. Embeds complete conversation history. Build upon history without repeating. Focus on new insights. Works across different tools."
                },
                "images": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Optional: Architecture diagrams, security models, threat models (absolute paths). Only if assists security assessment."
                },
                "model": {
                    "type": "string",
                    "description": "IMPORTANT: Use the model specified by the user if provided, OR select the most suitable model for this specific task based on the requirements and capabilities listed below:\n\nOpenAI models - Available when OPENAI_API_KEY is configured:\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'gpt-5-mini': GPT-5-mini (400K context, 128K output) - Efficient variant with reasoning support\n- 'gpt-5-nano': GPT-5 nano (400K context) - Fastest, cheapest version of GPT-5 for summarization and classification tasks\n- 'o3': Strong reasoning (200K context) - Logical problems, code generation, systematic analysis\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window",
                    "enum": [
                        "gpt-4.1",
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt4.1",
                        "gpt5",
                        "gpt5-mini",
                        "gpt5-nano",
                        "gpt5mini",
                        "gpt5nano",
                        "mini",
                        "nano",
                        "o3",
                        "o3-mini",
                        "o3-pro",
                        "o3mini",
                        "o4-mini",
                        "o4mini"
                    ]
                },
                "security_scope": {
                    "type": "string",
                    "description": "Security context (web/mobile/API/enterprise/cloud). Include stack, user types, data sensitivity, threat landscape. This helps focus the security assessment appropriately."
                },
                "threat_level": {
                    "type": "string",
                    "enum": [
                        "low",
                        "medium",
                        "high",
                        "critical"
                    ],
                    "default": "medium",
                    "description": "Assess the threat level based on application context: 'low' (internal tools, low-risk data), 'medium' (customer-facing, business data), 'high' (financial, healthcare, regulated industry), 'critical' (payment processing, sensitive personal data). This guides prioritization."
                },
                "compliance_requirements": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "List applicable compliance frameworks and security standards (SOC2, PCI DSS, HIPAA, GDPR, ISO 27001, NIST). Include industry-specific requirements that affect security controls."
                },
                "audit_focus": {
                    "type": "string",
                    "enum": [
                        "owasp",
                        "compliance",
                        "infrastructure",
                        "dependencies",
                        "comprehensive"
                    ],
                    "default": "comprehensive",
                    "description": "Primary security focus areas for this audit (owasp, compliance, infrastructure, dependencies)"
                },
                "severity_filter": {
                    "type": "string",
                    "enum": [
                        "critical",
                        "high",
                        "medium",
                        "low",
                        "all"
                    ],
                    "default": "all",
                    "description": "Minimum severity level to report on the security issues found"
                }
            },
            "required": [
                "step",
                "step_number",
                "total_steps",
                "next_step_required",
                "findings",
                "model"
            ],
            "additionalProperties": false,
            "title": "SecauditRequest"
        }
    },
    {
        "name": "docgen",
        "description": "Generates comprehensive code documentation with systematic analysis of functions, classes, and complexity. Use for documentation generation, code analysis, complexity assessment, and API documentation. Analyzes code structure and patterns to create thorough documentation.",
        "parameters": {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "type": "object",
            "properties": {
                "step": {
                    "type": "string",
                    "description": "Current work step content and findings from your overall work"
                },
                "step_number": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Current step number in work sequence (starts at 1)"
                },
                "total_steps": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Estimated total steps needed to complete work"
                },
                "next_step_required": {
                    "type": "boolean",
                    "description": "Whether another work step is needed. When false, aim to reduce total_steps to match step_number to avoid mismatch."
                },
                "findings": {
                    "type": "string",
                    "description": "Important findings, evidence and insights discovered in this step"
                },
                "relevant_files": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Files identified as relevant to issue/goal (FULL absolute paths to real files/folders - DO NOT SHORTEN)"
                },
                "relevant_context": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Methods/functions identified as involved in the issue"
                },
                "issues_found": {
                    "type": "array",
                    "items": {
                        "type": "object"
                    },
                    "description": "Issues identified with severity levels during work"
                },
                "use_assistant_model": {
                    "type": "boolean",
                    "default": true,
                    "description": "Use assistant model for expert analysis after workflow steps. False skips expert analysis, relies solely on Claude's investigation. Defaults to True for comprehensive validation."
                },
                "continuation_id": {
                    "type": "string",
                    "description": "Unique thread continuation ID for multi-turn conversations. Reuse last continuation_id when continuing discussion (unless user provides different ID) using exact unique identifer. Embeds complete conversation history. Build upon history without repeating. Focus on new insights. Works across different tools."
                },
                "document_complexity": {
                    "type": "boolean",
                    "default": true,
                    "description": "Whether to include algorithmic complexity (Big O) analysis in function/method documentation. Default: true. When enabled, analyzes and documents the computational complexity of algorithms."
                },
                "document_flow": {
                    "type": "boolean",
                    "default": true,
                    "description": "Whether to include call flow and dependency information in documentation. Default: true. When enabled, documents which methods this function calls and which methods call this function."
                },
                "update_existing": {
                    "type": "boolean",
                    "default": true,
                    "description": "Whether to update existing documentation when it's found to be incorrect or incomplete. Default: true. When enabled, improves existing docs rather than just adding new ones."
                },
                "comments_on_complex_logic": {
                    "type": "boolean",
                    "default": true,
                    "description": "Whether to add inline comments around complex logic within functions. Default: true. When enabled, adds explanatory comments for non-obvious algorithmic steps."
                },
                "num_files_documented": {
                    "type": "integer",
                    "default": 0,
                    "minimum": 0,
                    "description": "Counter for fully documented files. Starts at 0. Increment only when a file is 100% complete. CRITICAL: Must equal 'total_files_to_document' to finish."
                },
                "total_files_to_document": {
                    "type": "integer",
                    "default": 0,
                    "minimum": 0,
                    "description": "Counter for total files needing documentation. Set in step 1 during discovery. This is the completion target for the 'num_files_documented' counter."
                }
            },
            "required": [
                "step",
                "step_number",
                "total_steps",
                "next_step_required",
                "findings",
                "document_complexity",
                "document_flow",
                "update_existing",
                "comments_on_complex_logic",
                "num_files_documented",
                "total_files_to_document"
            ],
            "additionalProperties": false,
            "title": "DocgenRequest"
        }
    },
    {
        "name": "analyze",
        "description": "Performs comprehensive code analysis with systematic investigation and expert validation. Use for architecture, performance, maintainability, and pattern analysis. Guides through structured code review and strategic planning.",
        "parameters": {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "type": "object",
            "properties": {
                "step": {
                    "type": "string",
                    "description": "The analysis plan. Step 1: State your strategy, including how you will map the codebase structure, understand business logic, and assess code quality, performance implications, and architectural patterns. Later steps: Report findings and adapt the approach as new insights emerge."
                },
                "step_number": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "The index of the current step in the analysis sequence, beginning at 1. Each step should build upon or revise the previous one."
                },
                "total_steps": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Your current estimate for how many steps will be needed to complete the analysis. Adjust as new findings emerge."
                },
                "next_step_required": {
                    "type": "boolean",
                    "description": "Set to true if you plan to continue the investigation with another step. False means you believe the analysis is complete and ready for expert validation."
                },
                "findings": {
                    "type": "string",
                    "description": "Summary of discoveries from this step, including architectural patterns, tech stack assessment, scalability characteristics, performance implications, maintainability factors, and strategic improvement opportunities. IMPORTANT: Document both strengths (good patterns, solid architecture) and concerns (tech debt, overengineering, unnecessary complexity). In later steps, confirm or update past findings with additional evidence."
                },
                "files_checked": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "List all files examined (absolute paths). Include even ruled-out files to track exploration path."
                },
                "relevant_files": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Subset of files_checked directly relevant to analysis findings (absolute paths). Include files with significant patterns, architectural decisions, or strategic improvement opportunities."
                },
                "relevant_context": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Methods/functions identified as involved in the issue"
                },
                "issues_found": {
                    "type": "array",
                    "items": {
                        "type": "object"
                    },
                    "description": "Issues or concerns identified during analysis, each with severity level (critical, high, medium, low)"
                },
                "backtrack_from_step": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "If an earlier finding needs revision, specify the step number to backtrack from."
                },
                "use_assistant_model": {
                    "type": "boolean",
                    "default": true,
                    "description": "Use assistant model for expert analysis after workflow steps. False skips expert analysis, relies solely on Claude's investigation. Defaults to True for comprehensive validation."
                },
                "temperature": {
                    "type": "number",
                    "description": "Lower values: focused/deterministic; higher: creative. Tool-specific defaults apply if unspecified.",
                    "minimum": 0.0,
                    "maximum": 1.0
                },
                "thinking_mode": {
                    "type": "string",
                    "enum": [
                        "minimal",
                        "low",
                        "medium",
                        "high",
                        "max"
                    ],
                    "description": "Thinking depth: minimal (0.5%), low (8%), medium (33%), high (67%), max (100% of model max). Higher modes: deeper reasoning but slower."
                },
                "use_websearch": {
                    "type": "boolean",
                    "description": "Enable web search for docs and current info. Model can request Claude to perform web-search for best practices, framework docs, solution research, latest API information.",
                    "default": true
                },
                "continuation_id": {
                    "type": "string",
                    "description": "Unique thread continuation ID for multi-turn conversations. Reuse last continuation_id when continuing discussion (unless user provides different ID) using exact unique identifer. Embeds complete conversation history. Build upon history without repeating. Focus on new insights. Works across different tools."
                },
                "images": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Optional absolute paths to architecture diagrams or visual references that help with analysis context."
                },
                "model": {
                    "type": "string",
                    "description": "IMPORTANT: Use the model specified by the user if provided, OR select the most suitable model for this specific task based on the requirements and capabilities listed below:\n\nOpenAI models - Available when OPENAI_API_KEY is configured:\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'gpt-5-mini': GPT-5-mini (400K context, 128K output) - Efficient variant with reasoning support\n- 'gpt-5-nano': GPT-5 nano (400K context) - Fastest, cheapest version of GPT-5 for summarization and classification tasks\n- 'o3': Strong reasoning (200K context) - Logical problems, code generation, systematic analysis\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window",
                    "enum": [
                        "gpt-4.1",
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt4.1",
                        "gpt5",
                        "gpt5-mini",
                        "gpt5-nano",
                        "gpt5mini",
                        "gpt5nano",
                        "mini",
                        "nano",
                        "o3",
                        "o3-mini",
                        "o3-pro",
                        "o3mini",
                        "o4-mini",
                        "o4mini"
                    ]
                },
                "confidence": {
                    "type": "string",
                    "enum": [
                        "exploring",
                        "low",
                        "medium",
                        "high",
                        "very_high",
                        "almost_certain",
                        "certain"
                    ],
                    "description": "Your confidence in the analysis: exploring, low, medium, high, very_high, almost_certain, or certain. 'certain' indicates the analysis is complete and ready for validation."
                },
                "analysis_type": {
                    "type": "string",
                    "enum": [
                        "architecture",
                        "performance",
                        "security",
                        "quality",
                        "general"
                    ],
                    "default": "general",
                    "description": "Type of analysis to perform (architecture, performance, security, quality, general)"
                },
                "output_format": {
                    "type": "string",
                    "enum": [
                        "summary",
                        "detailed",
                        "actionable"
                    ],
                    "default": "detailed",
                    "description": "How to format the output (summary, detailed, actionable)"
                }
            },
            "required": [
                "step",
                "step_number",
                "total_steps",
                "next_step_required",
                "findings",
                "model"
            ],
            "additionalProperties": false,
            "title": "AnalyzeRequest"
        }
    },
    {
        "name": "refactor",
        "description": "Analyzes code for refactoring opportunities with systematic investigation. Use for code smell detection, decomposition planning, modernization, and maintainability improvements. Guides through structured analysis with expert validation.",
        "parameters": {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "type": "object",
            "properties": {
                "step": {
                    "type": "string",
                    "description": "The refactoring plan. Step 1: State strategy. Later steps: Report findings. CRITICAL: Examine code for smells, and opportunities for decomposition, modernization, and organization. Use 'relevant_files' for code. FORBIDDEN: Large code snippets."
                },
                "step_number": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "The index of the current step in the refactoring investigation sequence, beginning at 1. Each step should build upon or revise the previous one."
                },
                "total_steps": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Your current estimate for how many steps will be needed to complete the refactoring investigation. Adjust as new opportunities emerge."
                },
                "next_step_required": {
                    "type": "boolean",
                    "description": "Set to true if you plan to continue the investigation with another step. False means you believe the refactoring analysis is complete and ready for expert validation."
                },
                "findings": {
                    "type": "string",
                    "description": "Summary of discoveries from this step, including code smells and opportunities for decomposition, modernization, or organization. Document both strengths and weaknesses. In later steps, confirm or update past findings."
                },
                "files_checked": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "List all files examined (absolute paths). Include even ruled-out files to track exploration path."
                },
                "relevant_files": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Subset of files_checked with code requiring refactoring (absolute paths). Include files with code smells, decomposition needs, or improvement opportunities."
                },
                "relevant_context": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Methods/functions identified as involved in the issue"
                },
                "issues_found": {
                    "type": "array",
                    "items": {
                        "type": "object"
                    },
                    "description": "Refactoring opportunities as dictionaries with 'severity' (critical/high/medium/low), 'type' (codesmells/decompose/modernize/organization), and 'description'. Include all improvement opportunities found."
                },
                "confidence": {
                    "type": "string",
                    "enum": [
                        "exploring",
                        "incomplete",
                        "partial",
                        "complete"
                    ],
                    "default": "incomplete",
                    "description": "Your confidence in refactoring analysis: exploring (starting), incomplete (significant work remaining), partial (some opportunities found, more analysis needed), complete (comprehensive analysis finished, all major opportunities identified). WARNING: Use 'complete' ONLY when fully analyzed and can provide recommendations without expert help. 'complete' PREVENTS expert validation. Use 'partial' for large files or uncertain analysis."
                },
                "hypothesis": {
                    "type": "string",
                    "description": "Current theory about issue/goal based on work"
                },
                "backtrack_from_step": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "If an earlier finding needs revision, specify the step number to backtrack from."
                },
                "use_assistant_model": {
                    "type": "boolean",
                    "default": true,
                    "description": "Use assistant model for expert analysis after workflow steps. False skips expert analysis, relies solely on Claude's investigation. Defaults to True for comprehensive validation."
                },
                "temperature": {
                    "type": "number",
                    "description": "Lower values: focused/deterministic; higher: creative. Tool-specific defaults apply if unspecified.",
                    "minimum": 0.0,
                    "maximum": 1.0
                },
                "thinking_mode": {
                    "type": "string",
                    "enum": [
                        "minimal",
                        "low",
                        "medium",
                        "high",
                        "max"
                    ],
                    "description": "Thinking depth: minimal (0.5%), low (8%), medium (33%), high (67%), max (100% of model max). Higher modes: deeper reasoning but slower."
                },
                "use_websearch": {
                    "type": "boolean",
                    "description": "Enable web search for docs and current info. Model can request Claude to perform web-search for best practices, framework docs, solution research, latest API information.",
                    "default": true
                },
                "continuation_id": {
                    "type": "string",
                    "description": "Unique thread continuation ID for multi-turn conversations. Reuse last continuation_id when continuing discussion (unless user provides different ID) using exact unique identifer. Embeds complete conversation history. Build upon history without repeating. Focus on new insights. Works across different tools."
                },
                "images": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Optional list of absolute paths to architecture diagrams, UI mockups, design documents, or visual references that help with refactoring context. Only include if they materially assist understanding or assessment."
                },
                "model": {
                    "type": "string",
                    "description": "IMPORTANT: Use the model specified by the user if provided, OR select the most suitable model for this specific task based on the requirements and capabilities listed below:\n\nOpenAI models - Available when OPENAI_API_KEY is configured:\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'gpt-5-mini': GPT-5-mini (400K context, 128K output) - Efficient variant with reasoning support\n- 'gpt-5-nano': GPT-5 nano (400K context) - Fastest, cheapest version of GPT-5 for summarization and classification tasks\n- 'o3': Strong reasoning (200K context) - Logical problems, code generation, systematic analysis\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window",
                    "enum": [
                        "gpt-4.1",
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt4.1",
                        "gpt5",
                        "gpt5-mini",
                        "gpt5-nano",
                        "gpt5mini",
                        "gpt5nano",
                        "mini",
                        "nano",
                        "o3",
                        "o3-mini",
                        "o3-pro",
                        "o3mini",
                        "o4-mini",
                        "o4mini"
                    ]
                },
                "refactor_type": {
                    "type": "string",
                    "enum": [
                        "codesmells",
                        "decompose",
                        "modernize",
                        "organization"
                    ],
                    "default": "codesmells",
                    "description": "Type of refactoring analysis to perform (codesmells, decompose, modernize, organization)"
                },
                "focus_areas": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Specific areas to focus on (e.g., 'performance', 'readability', 'maintainability', 'security')"
                },
                "style_guide_examples": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Optional existing code files to use as style/pattern reference (must be FULL absolute paths to real files / folders - DO NOT SHORTEN). These files represent the target coding style and patterns for the project."
                }
            },
            "required": [
                "step",
                "step_number",
                "total_steps",
                "next_step_required",
                "findings",
                "model"
            ],
            "additionalProperties": false,
            "title": "RefactorRequest"
        }
    },
    {
        "name": "tracer",
        "description": "Performs systematic code tracing with modes for execution flow or dependency mapping. Use for method execution analysis, call chain tracing, dependency mapping, and architectural understanding. Supports precision mode (execution flow) and dependencies mode (structural relationships).",
        "parameters": {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "type": "object",
            "properties": {
                "step": {
                    "type": "string",
                    "description": "Current work step content and findings from your overall work"
                },
                "step_number": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Current step number in work sequence (starts at 1)"
                },
                "total_steps": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Estimated total steps needed to complete work"
                },
                "next_step_required": {
                    "type": "boolean",
                    "description": "Whether another work step is needed. When false, aim to reduce total_steps to match step_number to avoid mismatch."
                },
                "findings": {
                    "type": "string",
                    "description": "Important findings, evidence and insights discovered in this step"
                },
                "files_checked": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "List of files examined during this work step"
                },
                "relevant_files": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Files identified as relevant to issue/goal (FULL absolute paths to real files/folders - DO NOT SHORTEN)"
                },
                "relevant_context": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Methods/functions identified as involved in the issue"
                },
                "confidence": {
                    "type": "string",
                    "enum": [
                        "exploring",
                        "low",
                        "medium",
                        "high",
                        "very_high",
                        "almost_certain",
                        "certain"
                    ],
                    "description": "Confidence level: exploring (just starting), low (early investigation), medium (some evidence), high (strong evidence), very_high (comprehensive understanding), almost_certain (near complete confidence), certain (100% confidence locally - no external validation needed)"
                },
                "use_assistant_model": {
                    "type": "boolean",
                    "default": true,
                    "description": "Use assistant model for expert analysis after workflow steps. False skips expert analysis, relies solely on Claude's investigation. Defaults to True for comprehensive validation."
                },
                "continuation_id": {
                    "type": "string",
                    "description": "Unique thread continuation ID for multi-turn conversations. Reuse last continuation_id when continuing discussion (unless user provides different ID) using exact unique identifer. Embeds complete conversation history. Build upon history without repeating. Focus on new insights. Works across different tools."
                },
                "images": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Optional paths to architecture diagrams or flow charts that help understand the tracing context."
                },
                "model": {
                    "type": "string",
                    "description": "IMPORTANT: Use the model specified by the user if provided, OR select the most suitable model for this specific task based on the requirements and capabilities listed below:\n\nOpenAI models - Available when OPENAI_API_KEY is configured:\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'gpt-5-mini': GPT-5-mini (400K context, 128K output) - Efficient variant with reasoning support\n- 'gpt-5-nano': GPT-5 nano (400K context) - Fastest, cheapest version of GPT-5 for summarization and classification tasks\n- 'o3': Strong reasoning (200K context) - Logical problems, code generation, systematic analysis\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window",
                    "enum": [
                        "gpt-4.1",
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt4.1",
                        "gpt5",
                        "gpt5-mini",
                        "gpt5-nano",
                        "gpt5mini",
                        "gpt5nano",
                        "mini",
                        "nano",
                        "o3",
                        "o3-mini",
                        "o3-pro",
                        "o3mini",
                        "o4-mini",
                        "o4mini"
                    ]
                },
                "trace_mode": {
                    "type": "string",
                    "enum": [
                        "precision",
                        "dependencies",
                        "ask"
                    ],
                    "description": "Type of tracing: 'ask' (default - prompts user to choose mode), 'precision' (execution flow) or 'dependencies' (structural relationships)"
                },
                "target_description": {
                    "type": "string",
                    "description": "Description of what to trace and WHY. Include context about what you're trying to understand or analyze."
                }
            },
            "required": [
                "step",
                "step_number",
                "total_steps",
                "next_step_required",
                "findings",
                "target_description",
                "trace_mode",
                "model"
            ],
            "additionalProperties": false,
            "title": "TracerRequest"
        }
    },
    {
        "name": "testgen",
        "description": "Creates comprehensive test suites with edge case coverage for specific functions, classes, or modules. Analyzes code paths, identifies failure modes, and generates framework-specific tests. Be specific about scope - target particular components rather than testing everything.",
        "parameters": {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "type": "object",
            "properties": {
                "step": {
                    "type": "string",
                    "description": "The test plan for this step. Step 1: State strategy for analyzing code structure, business logic, critical paths, and edge cases. Later steps: Report findings and adapt as new test scenarios are identified."
                },
                "step_number": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "The index of the current step in the test generation sequence, beginning at 1. Each step should build upon or revise the previous one."
                },
                "total_steps": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Your current estimate for how many steps will be needed to complete the test generation analysis. Adjust as new findings emerge."
                },
                "next_step_required": {
                    "type": "boolean",
                    "description": "Set to true if you plan to continue the investigation with another step. False means you believe the test generation analysis is complete and ready for expert validation."
                },
                "findings": {
                    "type": "string",
                    "description": "Summary of discoveries about the code being tested. Include analysis of functionality, critical paths, edge cases, boundary conditions, and error handling. IMPORTANT: Document both happy paths and failure modes. Identify existing test patterns. In later steps, confirm or update past findings."
                },
                "files_checked": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "List all files examined (absolute paths). Include even ruled-out files to track exploration path."
                },
                "relevant_files": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Subset of files_checked containing code needing tests (absolute paths). Include implementation files, interfaces, dependencies, or existing test examples."
                },
                "relevant_context": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Methods/functions identified as involved in the issue"
                },
                "issues_found": {
                    "type": "array",
                    "items": {
                        "type": "object"
                    },
                    "description": "Issues identified with severity levels during work"
                },
                "confidence": {
                    "type": "string",
                    "enum": [
                        "exploring",
                        "low",
                        "medium",
                        "high",
                        "very_high",
                        "almost_certain",
                        "certain"
                    ],
                    "description": "Indicate your current confidence in the test generation assessment. Use: 'exploring' (starting analysis), 'low' (early investigation), 'medium' (some patterns identified), 'high' (strong understanding), 'very_high' (very strong understanding), 'almost_certain' (nearly complete test plan), 'certain' (100% confidence - test plan is thoroughly complete and all test scenarios are identified with no need for external model validation). Do NOT use 'certain' unless the test generation analysis is comprehensively complete, use 'very_high' or 'almost_certain' instead if not 100% sure. Using 'certain' means you have complete confidence locally and prevents external model validation."
                },
                "hypothesis": {
                    "type": "string",
                    "description": "Current theory about issue/goal based on work"
                },
                "backtrack_from_step": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "If an earlier finding needs revision, specify the step number to backtrack from."
                },
                "use_assistant_model": {
                    "type": "boolean",
                    "default": true,
                    "description": "Use assistant model for expert analysis after workflow steps. False skips expert analysis, relies solely on Claude's investigation. Defaults to True for comprehensive validation."
                },
                "temperature": {
                    "type": "number",
                    "description": "Lower values: focused/deterministic; higher: creative. Tool-specific defaults apply if unspecified.",
                    "minimum": 0.0,
                    "maximum": 1.0
                },
                "thinking_mode": {
                    "type": "string",
                    "enum": [
                        "minimal",
                        "low",
                        "medium",
                        "high",
                        "max"
                    ],
                    "description": "Thinking depth: minimal (0.5%), low (8%), medium (33%), high (67%), max (100% of model max). Higher modes: deeper reasoning but slower."
                },
                "use_websearch": {
                    "type": "boolean",
                    "description": "Enable web search for docs and current info. Model can request Claude to perform web-search for best practices, framework docs, solution research, latest API information.",
                    "default": true
                },
                "continuation_id": {
                    "type": "string",
                    "description": "Unique thread continuation ID for multi-turn conversations. Reuse last continuation_id when continuing discussion (unless user provides different ID) using exact unique identifer. Embeds complete conversation history. Build upon history without repeating. Focus on new insights. Works across different tools."
                },
                "images": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Optional list of absolute paths to architecture diagrams, flow charts, or visual documentation that help understand the code structure and test requirements. Only include if they materially assist test planning."
                },
                "model": {
                    "type": "string",
                    "description": "IMPORTANT: Use the model specified by the user if provided, OR select the most suitable model for this specific task based on the requirements and capabilities listed below:\n\nOpenAI models - Available when OPENAI_API_KEY is configured:\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'gpt-5-mini': GPT-5-mini (400K context, 128K output) - Efficient variant with reasoning support\n- 'gpt-5-nano': GPT-5 nano (400K context) - Fastest, cheapest version of GPT-5 for summarization and classification tasks\n- 'o3': Strong reasoning (200K context) - Logical problems, code generation, systematic analysis\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window\n- 'gpt-5': GPT-5 (400K context, 128K output) - Advanced model with reasoning support\n- 'o3-mini': Fast O3 variant (200K context) - Balanced performance/speed, moderate complexity\n- 'o3-pro': Professional-grade reasoning (200K context) - EXTREMELY EXPENSIVE: Only for the most complex problems requiring universe-scale complexity analysis OR when the user explicitly asks for this model. Use sparingly for critical architectural decisions or exceptionally complex debugging that other models cannot handle.\n- 'o4-mini': Latest reasoning model (200K context) - Optimized for shorter contexts, rapid reasoning\n- 'gpt-4.1': GPT-4.1 (1M context) - Advanced reasoning model with large context window",
                    "enum": [
                        "gpt-4.1",
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt4.1",
                        "gpt5",
                        "gpt5-mini",
                        "gpt5-nano",
                        "gpt5mini",
                        "gpt5nano",
                        "mini",
                        "nano",
                        "o3",
                        "o3-mini",
                        "o3-pro",
                        "o3mini",
                        "o4-mini",
                        "o4mini"
                    ]
                }
            },
            "required": [
                "step",
                "step_number",
                "total_steps",
                "next_step_required",
                "findings",
                "model"
            ],
            "additionalProperties": false,
            "title": "TestgenRequest"
        }
    },
    {
        "name": "challenge",
        "description": "Prevents reflexive agreement when users challenge responses by forcing critical thinking and reasoned analysis. Trigger automatically when users critically question, disagree with, or appear to challenge previous statements in ongoing conversations. Promotes truth-seeking over compliance by ensuring thoughtful evaluation rather than automatic agreement.",
        "parameters": {
            "type": "object",
            "properties": {
                "prompt": {
                    "type": "string",
                    "description": "The user's message or statement to analyze critically. When manually invoked with 'challenge', exclude that prefix - just pass the actual content. For automatic invocations (see tool description for conditions), pass the user's complete message unchanged."
                }
            },
            "required": [
                "prompt"
            ]
        }
    },
    {
        "name": "listmodels",
        "description": "Shows which AI model providers are configured, available model names, their aliases and capabilities.",
        "parameters": {
            "type": "object",
            "properties": {
                "model": {
                    "type": "string",
                    "description": "Model to use (ignored by listmodels tool)"
                }
            },
            "required": []
        }
    },
    {
        "name": "version",
        "description": "Get server version, configuration details, and list of available tools.",
        "parameters": {
            "type": "object",
            "properties": {
                "model": {
                    "type": "string",
                    "description": "Model to use (ignored by version tool)"
                }
            },
            "required": []
        }
    }
]