[
    {
        "name": "anthropic-chat",
        "description": "The Chat API. [See the documentation](https://docs.anthropic.com/claude/reference/messages_post)",
        "parameters": {
            "type": "object",
            "properties": {
                "model": {
                    "type": "string",
                    "description": "Select the model to use for your query. Defaults to the latest Claude model - [see the documentation](https://docs.anthropic.com/en/docs/about-claude/models/overview) for more information"
                },
                "userMessage": {
                    "type": "string",
                    "description": "The user messages provide instructions to the assistant"
                },
                "messages": {
                    "type": "string",
                    "description": "All relevant information must be supplied via the conversation. You can provide an array of messages from prior conversations here always beginning with the human message."
                },
                "temperature": {
                    "type": "string",
                    "description": "**Optional**. Amount of randomness injected into the response. Ranges from 0 to 1. Use temp closer to 0 for analytical / multiple choice, and temp closer to 1 for creative and generative tasks."
                },
                "topK": {
                    "type": "string",
                    "description": "Only sample from the top K options for each subsequent token. Used to remove `long tail` low probability responses."
                },
                "topP": {
                    "type": "string",
                    "description": "Does nucleus sampling, in which we compute the cumulative distribution over all the options for each subsequent token in decreasing probability order and cut it off once it reaches a particular probability specified."
                },
                "maxTokensToSample": {
                    "type": "string",
                    "description": "A maximum number of tokens to generate before stopping."
                }
            },
            "required": []
        }
    }
]